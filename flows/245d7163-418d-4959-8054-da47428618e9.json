{
  "nodes": [
    {
      "id": "a0645439-5569-4f1b-a41b-4a48deca5e77",
      "data": {
        "name": "constant_node",
        "description": "Describe the task of node python_node_0",
        "python_code": "def exec(myinput):\n  params = {\n    \"database_code\": \"alpdev_pg\",\n    \"schema_name\": \"cdmdefault\",\n    \"note_table\": \"note\",\n    \"note_nlp_table\": \"note_npl\",\n    \"use_cache_db\": False\n  }\n  return params\n"
      },
      "type": "python_node",
      "width": 350,
      "height": 210,
      "dragging": false,
      "position": {
        "x": -540,
        "y": -540
      },
      "selected": false,
      "dragHandle": "",
      "sourcePosition": "right",
      "targetPosition": "left",
      "positionAbsolute": {
        "x": -540,
        "y": -540
      }
    },
    {
      "id": "d6784351-b931-40a3-ab5e-9663b7a156fd",
      "data": {
        "name": "nel_node",
        "description": "Describe the task of node python_node_1",
        "python_code": "import pandas as pd\nimport spacy\nfrom scispacy.linking import EntityLinker\nfrom scispacy.abbreviation import AbbreviationDetector\nfrom prefect.logging import get_run_logger\n\nclass EntityExtractorLinker(object):\n  def __init__(self, mapper) -> None:\n    self.pipelines= list()\n    self.mapper = mapper\n\n    def add_pipeline(self, model_name:str, linker_name:str):\n      logger = get_run_logger()\n      logger.info(f\"Adding pipeline for model '{model_name}' and linker '{linker_name}'\")\n      logger.info(f\"Loading model ...\")\n      nlp = spacy.load(model_name) \n      logger.info(f\"Adding pipe ...\")\n      nlp.add_pipe(\"abbreviation_detector\")\n      logger.info(\"Loading linker ...\")\n      nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"linker_name\": linker_name})\n      logger.info(\"Adding pipeline done\")\n      self.pipelines.append((model_name, linker_name, nlp))\n\n    def extract_entities(self, text:str, confidence_threshold:float=0.8):\n      logger = get_run_logger()\n      if len(self.pipelines) == 0:\n        logger.info(\"No NLP pipeline defined - use 'add_pipeline' before calling 'extract_entities'!\")\n        return None\n        \n      data = dict()    \n      for model_name, linker_name, nlp in self.pipelines:\n        linker = nlp.get_pipe(\"scispacy_linker\")\n        doc = nlp(text)\n        logger.info(f\"Found {len(doc.ents)} entities.\")\n\n        for entity in doc.ents:\n          # list of matches in knowledge base (e.g. in case of UMLS, list of (cui_code, match_probability) tuples):\n          kb_matches = entity._.kb_ents\n          if len(kb_matches)==0:\n              logger.info(f\"No knowledge base mapping found for entity '{entity}'. Skipping.\")\n              continue\n\n          code, confidence = kb_matches[0]\n          if confidence < confidence_threshold:\n            logger.info(f\"Confidence below threshold ({confidence} < {confidence_threshold}) for entity '{entity}'. Skipping.\")\n            continue\n          \n          #convert CUI codes to rxNorm or SNOMED\n          mappings = self.mapper.get_codes(code)\n          if not any(key in mappings for key in [\"RxNorm\",\"SNOMED\"]):\n            logger.info(\"No mapping found for UMLS CUI '{code}' to either RxNorm or SNOMED. Skipping.\")\n            continue\n\n          omop_code, vocabulary = (mappings.get(\"RxNorm\"), \"RxNorm\") if \"RxNorm\" in mappings else (mappings.get(\"SNOMED\"), \"SNOMED\")               \n          data.setdefault(\"raw_text\", list()).append(text[entity.start_char:entity.end_char])\n          data.setdefault(\"start\", list()).append(entity.start_char)\n          data.setdefault(\"end\", list()).append(entity.end_char)\n          data.setdefault(\"label\", list()).append(entity.label_)\n          data.setdefault(\"model\", list()).append(model_name)\n          data.setdefault(\"linker\", list()).append(linker_name)\n\n          kb_entity = linker.kb.cui_to_entity[code]\n          data.setdefault(\"concept_id\", list()).append(omop_code)\n          data.setdefault(\"vocabulary\", list()).append(vocabulary)\n          data.setdefault(\"confidence\", list()).append(confidence)\n          data.setdefault(\"UMLS_canonical_name\", list()).append(kb_entity.canonical_name)\n          data.setdefault(\"UMLS_definition\", list()).append(kb_entity.definition)\n  \n      return pd.DataFrame(data)\n\ndef exec(myinput):\n  return EntityExtractorLinker"
      },
      "type": "python_node",
      "width": 354,
      "height": 214,
      "position": {
        "x": -440,
        "y": -440
      },
      "selected": false,
      "dragHandle": "",
      "sourcePosition": "right",
      "targetPosition": "left"
    },
    {
      "id": "c0639286-a0c3-4212-9fe5-8ac2df909c31",
      "type": "python_node",
      "data": {
        "name": "umls2omop_node",
        "description": "Describe the task of node python_node_2",
        "python_code": "import pandas as pd\nfrom typing import List, Union\n\nCUItoOHDSI_CSV=f\"flows/nlp/ner_extract_plugin/external/CUItoOHDSIv1.csv\"\n\nclass CIO2OMOP(object):\n    def __init__(self, mapping_csv: str) -> None:\n        with open(mapping_csv, 'r') as in_mappings:\n            self.mappings_df = pd.read_csv(in_mappings, index_col=0)\n            self.coding_systems = list(self.mappings_df[\"vocabulary_id\"].unique())\n\n    def get_supported_vocabulaires(self) -> List[str]:\n        return self.coding_systems\n\n    def get_codes(self, CUI:str):\n        try:\n            results = self.mappings_df.loc[[CUI]]\n        except KeyError:\n            # CUI code not found\n            return dict()\n        \n        return dict([(vocabulary_id, (results.loc[results[\"vocabulary_id\"]==vocabulary_id][\"concept_id\"]).squeeze()) \n                     for vocabulary_id in results[\"vocabulary_id\"]])\n\n    def get_mappings(self, CUI:Union[str,List[str]]):\n        return self.mappings_df.loc[CUI]\n\ndef exec(myinput):\n  mapper = CIO2OMOP(mapping_csv=CUItoOHDSI_CSV)\n  return mapper"
      },
      "position": {
        "x": -340,
        "y": -340
      },
      "width": 354,
      "height": 214,
      "selected": true,
      "sourcePosition": "right",
      "targetPosition": "left",
      "dragHandle": ""
    }
  ],
  "edges": [],
  "variables": [
    {
      "key": "a",
      "value": "1"
    }
  ],
  "importLibs": [
    "pandas"
  ]
}